{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action Grammars: A Grammar-Induction Based Method for Learning Temporal Abstractions\n",
    "## Authors: Robert Lange and Aldo Faisal | April 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "import gym_hanoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.q_agent import Agent_Q\n",
    "from agents.smdp_q_agent import SMDP_Agent_Q, Macro, SMDPQTable\n",
    "# from agents.a2c_agent import ActorCritic, train_a2c_agent\n",
    "\n",
    "from learning.q_learning import  q_learning\n",
    "from learning.smdp_q_learning import smdp_q_learning, smdp_q_online_learning\n",
    "\n",
    "from learning.learning_params import *\n",
    "from learning.run_learning import *\n",
    "\n",
    "from utils.general import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory - Learning performance\n",
    "results_dir = os.getcwd() + \"/results/\"\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    print(\"Created New Results Directory\")\n",
    "\n",
    "# Create directory - Log directory\n",
    "log_dir = os.getcwd() + \"/logs/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    print(\"Created New Log Directory\")\n",
    "    \n",
    "# Create directory - Figure directory\n",
    "fig_dir = os.getcwd() + \"/figures/\"\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "    print(\"Created New Fig Directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towers of Hanoi - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.8, 'gamma': 0.95, 'lambd': 0.1, 'epsilon': 0.1}\n",
      "{'alpha': 0.8, 'gamma': 0.95, 'lambd': 0.0, 'epsilon': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(learning_parameters(\"Q-Learning\"))\n",
    "print(learning_parameters(\"Imitation-SMDP-Q-Learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_setup = {4: {\"num_episodes\": 1000,\n",
    "                      \"max_steps\": 500},\n",
    "                  5: {\"num_episodes\": 1250,\n",
    "                      \"max_steps\": 1000},\n",
    "                  6: {\"num_episodes\": 5000,\n",
    "                      \"max_steps\": 2000},\n",
    "                  7: {\"num_episodes\": 10000,\n",
    "                      \"max_steps\": 4000},\n",
    "                  8: {\"num_episodes\": 20000,\n",
    "                      \"max_steps\": 8000}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple TD($\\lambda$) Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rtl/anaconda2/envs/AG/lib/python3.6/site-packages/gym-0.10.9-py3.6.egg/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# Setup for N=4 Disk Towers of Hanoi Environment\n",
    "log_episodes = 1\n",
    "log_freq = 20\n",
    "\n",
    "N = 4\n",
    "num_episodes = learning_setup[N][\"num_episodes\"]\n",
    "max_steps = learning_setup[N][\"max_steps\"]\n",
    "\n",
    "env = gym.make(\"Hanoi-v0\")\n",
    "env.set_env_parameters(N, env_noise=0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:  1 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 21 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 41 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 61 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 81 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 101 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 121 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 141 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 161 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 181 | Avg/Std Steps: 22.00/0.00 | Avg/Std Ret: 34.06/0.00 | Success R: 1.00\n",
      "Ep: 201 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 221 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 241 | Avg/Std Steps: 21.00/0.00 | Avg/Std Ret: 35.85/0.00 | Success R: 1.00\n",
      "Ep: 261 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 281 | Avg/Std Steps: 22.00/0.00 | Avg/Std Ret: 34.06/0.00 | Success R: 1.00\n",
      "Ep: 301 | Avg/Std Steps: 20.00/0.00 | Avg/Std Ret: 37.74/0.00 | Success R: 1.00\n",
      "Ep: 321 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 341 | Avg/Std Steps: 20.00/0.00 | Avg/Std Ret: 37.74/0.00 | Success R: 1.00\n",
      "Ep: 361 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 381 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 401 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 421 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 441 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 461 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 481 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 501 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 521 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 541 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 561 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 581 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 601 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 621 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 641 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 661 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 681 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 701 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 721 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 741 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 761 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 781 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 801 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 821 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 841 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 861 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 881 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 901 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 921 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 941 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 961 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 981 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n"
     ]
    }
   ],
   "source": [
    "agent = Agent_Q(env)\n",
    "params = learning_parameters(l_type=\"Q-Learning\")\n",
    "hist, er_buffer = q_learning(env, agent, num_episodes, max_steps,\n",
    "                             **params, log_freq=log_freq,\n",
    "                             log_episodes=log_episodes, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Disks - Q-Learning: Run 1/5 Done - Time: 1.14\n",
      "4 Disks - Q-Learning: Run 2/5 Done - Time: 1.8\n",
      "4 Disks - Q-Learning: Run 3/5 Done - Time: 3.47\n",
      "4 Disks - Q-Learning: Run 4/5 Done - Time: 2.56\n",
      "4 Disks - Q-Learning: Run 5/5 Done - Time: 1.15\n",
      "Outfiled the results to results/4_disks_q.txt.\n"
     ]
    }
   ],
   "source": [
    "# Run Learning 5 times for 4 Disk Environment\n",
    "num_times = 5\n",
    "num_disks = 4\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "stats_4_q = run_learning(\"Q-Learning\", num_times, num_disks,\n",
    "                         num_episodes, max_steps,\n",
    "                         log_episodes, log_freq,\n",
    "                         save_fname=\"results/4_disks_q.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Learning 5 times for 5 Disk Environment\n",
    "num_times = 5\n",
    "num_disks = 5\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "stats_5_q = run_learning(\"Q-Learning\", num_times, num_disks,\n",
    "                         num_episodes, max_steps,\n",
    "                         log_episodes, log_freq,\n",
    "                         save_fname=\"results/5_disks_q.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Learning 5 times for 6 Disk Environment\n",
    "num_times = 5\n",
    "num_disks = 6\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "stats_6_q = run_learning(\"Q-Learning\", num_times, num_disks,\n",
    "                         num_episodes, max_steps,\n",
    "                         log_episodes, log_freq,\n",
    "                         save_fname=\"results/6_disks_q.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a greedy rollout Experience Replay Episode\n",
    "get_rollout_policy(env, agent, max_steps, grammar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rollout_policy(env, agent, max_steps, grammar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Context-Free Grammar Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_policies = {4: \"abdaefabdcedabd\",\n",
    "                    5: \"bafbcdbafecfbafbcdbcfecdbafbcdb\",\n",
    "                    6: \"abdaefabdcedabdaefaedcefabdaefabdcedabdce\"\\\n",
    "                        \"faedcedabdaefabdcedabd\",\n",
    "                    7: \"bafbcdbafecfbafbcdbcfecdbafbcdbafecfbafec\"\\\n",
    "                        \"dbcfecfbafbcdbafecfbafbcdbcfecdbafbcdbcfe\"\\\n",
    "                        \"cfbafecdbcfecdbafbcdbafecfbafbcdbcfecdbafbcdb\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammars.cfg_grammar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_macros(\"all\", optimal_policies[4], 6, \"sequitur\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_macros(\"all\", optimal_policies[4], 6, \"lexis\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imitation SMDP-Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_episodes = 10\n",
    "log_freq = 20\n",
    "\n",
    "N = 4\n",
    "num_episodes = learning_setup[N][\"num_episodes\"]\n",
    "max_steps = learning_setup[N][\"max_steps\"]\n",
    "\n",
    "env = gym.make(\"Hanoi-v0\")\n",
    "env.set_env_parameters(num_disks=N, env_noise=0, verbose=False)\n",
    "\n",
    "macros = get_optimal_macros(env, N, \"Sequitur\")\n",
    "agent = SMDP_Agent_Q(env, macros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:  1 | Avg/Std Steps: 219.56/119.91 | Avg/Std Ret: 0.83/119.91 | Success R: 0.90\n",
      "Ep: 21 | Avg/Std Steps: 169.14/139.64 | Avg/Std Ret: 5.68/139.64 | Success R: 0.70\n",
      "Ep: 41 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 61 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 81 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 101 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 121 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 141 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 161 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 181 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 201 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 221 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 241 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 261 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 281 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 301 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 321 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 341 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 361 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 381 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 401 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 421 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 441 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 461 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 481 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 501 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 521 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 541 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 561 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 581 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 601 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 621 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 641 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 661 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 681 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 701 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 721 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 741 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 761 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 781 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 801 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 821 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 841 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 861 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 881 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 901 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 921 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 941 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 961 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n",
      "Ep: 981 | Avg/Std Steps: 15.00/0.00 | Avg/Std Ret: 48.77/0.00 | Success R: 1.00\n"
     ]
    }
   ],
   "source": [
    "params = learning_parameters(l_type=\"Imitation-SMDP-Q-Learning\")\n",
    "hist, er_buffer = smdp_q_learning(env, agent, num_episodes, max_steps,\n",
    "                                  **params,\n",
    "                                  log_freq=log_freq,\n",
    "                                  log_episodes=log_episodes, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Disks - Imitation-SMDP-Q-Learning: Run 1/5 Done - Time: 1.2\n",
      "4 Disks - Imitation-SMDP-Q-Learning: Run 2/5 Done - Time: 1.07\n",
      "4 Disks - Imitation-SMDP-Q-Learning: Run 3/5 Done - Time: 1.08\n",
      "4 Disks - Imitation-SMDP-Q-Learning: Run 4/5 Done - Time: 1.09\n",
      "4 Disks - Imitation-SMDP-Q-Learning: Run 5/5 Done - Time: 1.37\n",
      "Outfiled the results to results/4_disks_smdp_imi.txt.\n"
     ]
    }
   ],
   "source": [
    "# Run Learning 5 times for 4 Disk Environment\n",
    "num_times = 5\n",
    "num_disks = 4\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "stats_4_smdp_imi = run_learning(\"Imitation-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                num_episodes, max_steps,\n",
    "                                log_episodes, log_freq,\n",
    "                                save_fname=\"results/4_disks_smdp_imi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Disks - Imitation-SMDP-Q-Learning: Run 1/5 Done - Time: 4.72\n",
      "5 Disks - Imitation-SMDP-Q-Learning: Run 2/5 Done - Time: 3.3\n",
      "5 Disks - Imitation-SMDP-Q-Learning: Run 3/5 Done - Time: 3.5\n",
      "5 Disks - Imitation-SMDP-Q-Learning: Run 4/5 Done - Time: 3.47\n",
      "5 Disks - Imitation-SMDP-Q-Learning: Run 5/5 Done - Time: 3.19\n",
      "Outfiled the results to results/5_disks_smdp_imi.txt.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f35b439a5235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                             \u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                             \u001b[0mlog_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                             save_fname=\"results/5_disks_smdp_imi.txt\")\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Run Learning 5 times for 5 Disk Environment\n",
    "num_disks = 5\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "env, agent, stats_5_smdp_imi = run_learning(\"Imitation-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                            num_episodes, max_steps,\n",
    "                                            log_episodes, log_freq,\n",
    "                                            save_fname=\"results/5_disks_smdp_imi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Learning 5 times for 6 Disk Environment\n",
    "num_disks = 6\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "stats_6_smdp_imi = run_learning(\"Imitation-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                num_episodes, max_steps,\n",
    "                                log_episodes, log_freq,\n",
    "                                save_fname=\"results/6_disks_smdp_imi.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_episodes = 10\n",
    "log_freq = 20\n",
    "\n",
    "N = 5\n",
    "num_episodes = learning_setup[N][\"num_episodes\"]\n",
    "max_steps = learning_setup[N][\"max_steps\"]\n",
    "\n",
    "env = gym.make(\"Hanoi-v0\")\n",
    "env.set_env_parameters(num_disks=N, env_noise=0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macros = get_optimal_macros(env, N-1, \"Sequitur\")\n",
    "agent = SMDP_Agent_Q(env, macros)\n",
    "params = learning_parameters(l_type=\"Transfer-SMDP-Q-Learning\")\n",
    "hist, er_buffer = smdp_q_learning(env, agent, num_episodes, max_steps,\n",
    "                                  **params,\n",
    "                                  log_freq=log_freq,\n",
    "                                  log_episodes=log_episodes, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Learning 5 times for 5 Disk Environment with 4 disk grammar\n",
    "num_times = 5\n",
    "num_disks = 5\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "env, agent, stats_smdp_trans_5 = run_learning(\"Transfer-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                              num_episodes, max_steps,\n",
    "                                              log_episodes, log_freq,\n",
    "                                              transfer_distance=1,\n",
    "                                              save_fname=\"results/5_disks_smdp_transfer_4_disks.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times = 5\n",
    "num_disks = 6\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "\n",
    "# Run Learning 5 times for 6 Disk Environment with 5 disk grammar\n",
    "env, agent, stats_smdp_trans_5 = run_learning(\"Transfer-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                              num_episodes, max_steps,\n",
    "                                              log_episodes, log_freq,\n",
    "                                              transfer_distance=1,\n",
    "                                              save_fname=\"results/6_disks_smdp_transfer_5_disks.txt\")\n",
    "\n",
    "# Run Learning 5 times for 6 Disk Environment with 4 disk grammar\n",
    "env, agent, stats_smdp_trans_4 = run_learning(\"Transfer-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                              num_episodes, max_steps,\n",
    "                                              log_episodes, log_freq,\n",
    "                                              transfer_distance=2,\n",
    "                                              save_fname=\"results/6_disks_smdp_transfer_4_disks.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online-Grammar-Macro-SMDP Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for N=4 Disk Towers of Hanoi Environment\n",
    "log_episodes = 10\n",
    "log_freq = 20\n",
    "\n",
    "init_q_eps = 20\n",
    "inter_update_eps=100\n",
    "num_grammar_updates=5\n",
    "\n",
    "N = 4\n",
    "max_steps = learning_setup[N][\"max_steps\"]\n",
    "\n",
    "env = gym.make(\"Hanoi-v0\")\n",
    "env.set_env_parameters(N, env_noise=0, verbose=False)\n",
    "\n",
    "params = learning_parameters(l_type=\"Q-Learning\")\n",
    "hist = smdp_q_online_learning(env, init_q_eps, inter_update_eps,\n",
    "                              num_grammar_updates, max_steps, **params,\n",
    "                              log_freq=log_freq, log_episodes=log_episodes,\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Learning 5 times for 5 Disk Environment\n",
    "num_disks = 4\n",
    "stats_smdp_online = run_learning(\"Online-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                 num_episodes, max_steps,\n",
    "                                 log_episodes, log_freq,\n",
    "                                 save_fname=\"results/4_disks_smdp_online_no_transfer.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (AG)",
   "language": "python",
   "name": "ag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
