{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Action Grammars: A Grammar-Induction Based Method for Learning Temporally-Extended Actions\n",
    "## Authors: Robert Lange and Aldo Faisal | January 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "import gym_hanoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.q_agent import Agent_Q\n",
    "from agents.smdp_q_agent import SMDP_Agent_Q, Macro, SMDPQTable\n",
    "\n",
    "from learning.q_learning import  q_learning\n",
    "from learning.smdp_q_learning import smdp_q_learning, smdp_q_online_learning\n",
    "\n",
    "from learning.learning_params import *\n",
    "from learning.run_learning import *\n",
    "\n",
    "from utils.general import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory - Learning performance\n",
    "results_dir = os.getcwd() + \"/results/\"\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "    print(\"Created New Results Directory\")\n",
    "\n",
    "# Create directory - Log directory\n",
    "log_dir = os.getcwd() + \"/logs/\"\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "    print(\"Created New Log Directory\")\n",
    "    \n",
    "# Create directory - Figure directory\n",
    "fig_dir = os.getcwd() + \"/figures/\"\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "    print(\"Created New Fig Directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towers of Hanoi - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.8, 'gamma': 0.95, 'lambd': 0.1, 'epsilon': 0.1}\n",
      "{'alpha': 0.8, 'gamma': 0.95, 'lambd': 0.0, 'epsilon': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(learning_parameters(\"Q-Learning\"))\n",
    "print(learning_parameters(\"Imitation-SMDP-Q-Learning\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_setup = {4: {\"num_episodes\": 300,\n",
    "                      \"max_steps\": 500},\n",
    "                  5: {\"num_episodes\": 1250,\n",
    "                      \"max_steps\": 1000},\n",
    "                  6: {\"num_episodes\": 5000,\n",
    "                      \"max_steps\": 2000},\n",
    "                  7: {\"num_episodes\": 10000,\n",
    "                      \"max_steps\": 4000},\n",
    "                  8: {\"num_episodes\": 20000,\n",
    "                      \"max_steps\": 8000}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple TD($\\lambda$) Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rtl/anaconda2/envs/AG/lib/python3.6/site-packages/gym-0.10.9-py3.6.egg/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# Setup for N=4 Disk Towers of Hanoi Environment\n",
    "log_episodes = 10\n",
    "log_freq = 20\n",
    "\n",
    "N = 4\n",
    "num_episodes = learning_setup[N][\"num_episodes\"]\n",
    "max_steps = learning_setup[N][\"max_steps\"]\n",
    "\n",
    "env = gym.make(\"Hanoi-v0\")\n",
    "env.set_env_parameters(N, env_noise=0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:  1 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 21 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 41 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 61 | Avg/Std Steps: 27.00/0.00 | Avg/Std Ret: 26.35/0.00 | Success R: 1.00\n",
      "Ep: 81 | Avg/Std Steps: 26.00/0.00 | Avg/Std Ret: 27.74/0.00 | Success R: 1.00\n",
      "Ep: 101 | Avg/Std Steps: 23.00/0.00 | Avg/Std Ret: 32.35/0.00 | Success R: 1.00\n",
      "Ep: 121 | Avg/Std Steps: 26.00/0.00 | Avg/Std Ret: 27.74/0.00 | Success R: 1.00\n",
      "Ep: 141 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 161 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 181 | Avg/Std Steps: 23.00/0.00 | Avg/Std Ret: 32.35/0.00 | Success R: 1.00\n",
      "Ep: 201 | Avg/Std Steps: 23.00/0.00 | Avg/Std Ret: 32.35/0.00 | Success R: 1.00\n",
      "Ep: 221 | Avg/Std Steps: 23.00/0.00 | Avg/Std Ret: 32.35/0.00 | Success R: 1.00\n",
      "Ep: 241 | Avg/Std Steps: 23.00/0.00 | Avg/Std Ret: 32.35/0.00 | Success R: 1.00\n",
      "Ep: 261 | Avg/Std Steps: 21.00/0.00 | Avg/Std Ret: 35.85/0.00 | Success R: 1.00\n",
      "Ep: 281 | Avg/Std Steps: 21.00/0.00 | Avg/Std Ret: 35.85/0.00 | Success R: 1.00\n"
     ]
    }
   ],
   "source": [
    "agent = Agent_Q(env)\n",
    "params = learning_parameters(l_type=\"Q-Learning\")\n",
    "hist, er_buffer = q_learning(env, agent, num_episodes, max_steps,\n",
    "                             **params, log_freq=log_freq,\n",
    "                             log_episodes=log_episodes, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Disks - Q-Learning: Run 1/5 Done - Time: 1.41\n",
      "4 Disks - Q-Learning: Run 2/5 Done - Time: 1.15\n",
      "4 Disks - Q-Learning: Run 3/5 Done - Time: 1.13\n",
      "4 Disks - Q-Learning: Run 4/5 Done - Time: 2.41\n",
      "4 Disks - Q-Learning: Run 5/5 Done - Time: 0.88\n",
      "Outfiled the results to results/4_disks_q.txt.\n"
     ]
    }
   ],
   "source": [
    "# Run Learning 5 times for 4 Disk Environment\n",
    "num_times = 5\n",
    "num_disks = 4\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "env, agent, stats_4_q = run_learning(\"Q-Learning\", num_times, num_disks,\n",
    "                                     num_episodes, max_steps,\n",
    "                                     log_episodes, log_freq,\n",
    "                                     save_fname=\"results/4_disks_q.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Disks - Q-Learning: Run 1/5 Done - Time: 16.61\n",
      "5 Disks - Q-Learning: Run 2/5 Done - Time: 20.75\n",
      "5 Disks - Q-Learning: Run 3/5 Done - Time: 17.17\n",
      "5 Disks - Q-Learning: Run 4/5 Done - Time: 16.8\n",
      "5 Disks - Q-Learning: Run 5/5 Done - Time: 26.66\n",
      "Outfiled the results to results/5_disks_q.txt.\n"
     ]
    }
   ],
   "source": [
    "# Run Learning 5 times for 5 Disk Environment\n",
    "num_disks = 5\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "env, agent, stats_5_q = run_learning(\"Q-Learning\", num_times, num_disks,\n",
    "                                     num_episodes, max_steps,\n",
    "                                     log_episodes, log_freq,\n",
    "                                     save_fname=\"results/5_disks_q.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Learning 5 times for 6 Disk Environment\n",
    "num_disks = 6\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "env, agent, stats_6_q = run_learning(\"Q-Learning\", num_times, num_disks,\n",
    "                                     num_episodes, max_steps,\n",
    "                                     log_episodes, log_freq,\n",
    "                                     save_fname=\"results/6_disks_q.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([(0, (0, 0, 0, 0, 0), 1, (2, 0, 0, 0, 0)),\n",
       "       (1, (2, 0, 0, 0, 0), 0, (2, 1, 0, 0, 0)),\n",
       "       (2, (2, 1, 0, 0, 0), 5, (1, 1, 0, 0, 0)),\n",
       "       (3, (1, 1, 0, 0, 0), 1, (1, 1, 2, 0, 0)),\n",
       "       (4, (1, 1, 2, 0, 0), 2, (0, 1, 2, 0, 0)),\n",
       "       (5, (0, 1, 2, 0, 0), 3, (0, 2, 2, 0, 0)),\n",
       "       (6, (0, 2, 2, 0, 0), 1, (2, 2, 2, 0, 0)),\n",
       "       (7, (2, 2, 2, 0, 0), 0, (2, 2, 2, 1, 0)),\n",
       "       (8, (2, 2, 2, 1, 0), 5, (1, 2, 2, 1, 0)),\n",
       "       (9, (1, 2, 2, 1, 0), 4, (1, 0, 2, 1, 0)),\n",
       "       (10, (1, 0, 2, 1, 0), 2, (0, 0, 2, 1, 0)),\n",
       "       (11, (0, 0, 2, 1, 0), 5, (0, 0, 1, 1, 0)),\n",
       "       (12, (0, 0, 1, 1, 0), 1, (2, 0, 1, 1, 0)),\n",
       "       (13, (2, 0, 1, 1, 0), 0, (2, 1, 1, 1, 0)),\n",
       "       (14, (2, 1, 1, 1, 0), 5, (1, 1, 1, 1, 0)),\n",
       "       (15, (1, 1, 1, 1, 0), 1, (1, 1, 1, 1, 2)),\n",
       "       (16, (1, 1, 1, 1, 2), 2, (0, 1, 1, 1, 2)),\n",
       "       (17, (0, 1, 1, 1, 2), 3, (0, 2, 1, 1, 2)),\n",
       "       (18, (0, 2, 1, 1, 2), 1, (2, 2, 1, 1, 2)),\n",
       "       (19, (2, 2, 1, 1, 2), 2, (2, 2, 0, 1, 2)),\n",
       "       (20, (2, 2, 0, 1, 2), 4, (0, 2, 0, 1, 2)),\n",
       "       (21, (0, 2, 0, 1, 2), 5, (0, 1, 0, 1, 2)),\n",
       "       (22, (0, 1, 0, 1, 2), 1, (2, 1, 0, 1, 2)),\n",
       "       (23, (2, 1, 0, 1, 2), 2, (2, 0, 0, 1, 2)),\n",
       "       (24, (2, 0, 0, 1, 2), 4, (0, 0, 0, 1, 2)),\n",
       "       (25, (0, 0, 0, 1, 2), 3, (0, 0, 0, 2, 2)),\n",
       "       (26, (0, 0, 0, 2, 2), 0, (1, 0, 0, 2, 2)),\n",
       "       (27, (1, 0, 0, 2, 2), 1, (1, 2, 0, 2, 2)),\n",
       "       (28, (1, 2, 0, 2, 2), 3, (2, 2, 0, 2, 2)),\n",
       "       (29, (2, 2, 0, 2, 2), 0, (2, 2, 1, 2, 2)),\n",
       "       (30, (2, 2, 1, 2, 2), 5, (1, 2, 1, 2, 2)),\n",
       "       (31, (1, 2, 1, 2, 2), 4, (1, 0, 1, 2, 2)),\n",
       "       (32, (1, 0, 1, 2, 2), 2, (0, 0, 1, 2, 2)),\n",
       "       (33, (0, 0, 1, 2, 2), 3, (0, 0, 2, 2, 2)),\n",
       "       (34, (0, 0, 2, 2, 2), 0, (1, 0, 2, 2, 2)),\n",
       "       (35, (1, 0, 2, 2, 2), 1, (1, 2, 2, 2, 2)),\n",
       "       (36, (1, 2, 2, 2, 2), 3, (2, 2, 2, 2, 2))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return a greedy rollout Experience Replay Episode\n",
    "get_rollout_policy(env, agent, max_steps, grammar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bafbcdbafecfbafbcdbcefbcedabdafecdabd'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_rollout_policy(env, agent, max_steps, grammar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Context-Free Grammar Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_policies = {4: \"abdaefabdcedabd\",\n",
    "                    5: \"bafbcdbafecfbafbcdbcfecdbafbcdb\",\n",
    "                    6: \"abdaefabdcedabdaefaedcefabdaefabdcedabdce\"\\\n",
    "                        \"faedcedabdaefabdcedabd\",\n",
    "                    7: \"bafbcdbafecfbafbcdbcfecdbafbcdbafecfbafec\"\\\n",
    "                        \"dbcfecfbafbcdbafecfbafbcdbcfecdbafbcdbcfe\"\\\n",
    "                        \"cfbafecdbcfecdbafbcdbafecfbafbcdbcfecdbafbcdb\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grammars.cfg_grammar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 a e f 1 c e d 1 \\\\n ', 'a b d ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['abd']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_macros(\"all\", optimal_policies[4], 6, \"sequitur\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_macros(\"all\", optimal_policies[4], 6, \"lexis\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imitation SMDP-Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_episodes = 10\n",
    "log_freq = 20\n",
    "\n",
    "N = 4\n",
    "num_episodes = learning_setup[N][\"num_episodes\"]\n",
    "max_steps = learning_setup[N][\"max_steps\"]\n",
    "\n",
    "env = gym.make(\"Hanoi-v0\")\n",
    "env.set_env_parameters(num_disks=N, env_noise=0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:  1 | Avg/Std Steps: 182.86/96.46 | Avg/Std Ret: 0.28/96.46 | Success R: 0.70\n",
      "Ep: 21 | Avg/Std Steps: 146.33/103.63 | Avg/Std Ret: 4.00/103.63 | Success R: 0.30\n",
      "Ep: 41 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 61 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 81 | Avg/Std Steps: 18.00/0.00 | Avg/Std Ret: 41.81/0.00 | Success R: 1.00\n",
      "Ep: 101 | Avg/Std Steps: 18.00/0.00 | Avg/Std Ret: 41.81/0.00 | Success R: 1.00\n",
      "Ep: 121 | Avg/Std Steps: 18.00/0.00 | Avg/Std Ret: 41.81/0.00 | Success R: 1.00\n",
      "Ep: 141 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 161 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 181 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 201 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 221 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 241 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 261 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 281 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n"
     ]
    }
   ],
   "source": [
    "macros = get_optimal_macros(env, N, \"Sequitur\")\n",
    "agent = SMDP_Agent_Q(env, macros)\n",
    "params = learning_parameters(l_type=\"Imitation-SMDP-Q-Learning\")\n",
    "hist, er_buffer = smdp_q_learning(env, agent, num_episodes, max_steps,\n",
    "                                  **params,\n",
    "                                  log_freq=log_freq,\n",
    "                                  log_episodes=log_episodes, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Disks - Imitation-SMDP-Q-Learning: Run 1/5 Done - Time: 1.3\n",
      "4 Disks - Imitation-SMDP-Q-Learning: Run 2/5 Done - Time: 1.07\n",
      "4 Disks - Imitation-SMDP-Q-Learning: Run 3/5 Done - Time: 1.12\n",
      "4 Disks - Imitation-SMDP-Q-Learning: Run 4/5 Done - Time: 1.39\n",
      "4 Disks - Imitation-SMDP-Q-Learning: Run 5/5 Done - Time: 1.32\n",
      "Outfiled the results to results/4_disks_smdp_imi.txt.\n"
     ]
    }
   ],
   "source": [
    "# Run Learning 5 times for 4 Disk Environment\n",
    "num_times = 5\n",
    "num_disks = 4\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "env, agent, stats_4_smdp_imi = run_learning(\"Imitation-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                            num_episodes, max_steps,\n",
    "                                            log_episodes, log_freq,\n",
    "                                            save_fname=\"results/4_disks_smdp_imi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Disks - Imitation-SMDP-Q-Learning: Run 1/5 Done - Time: 23.63\n",
      "5 Disks - Imitation-SMDP-Q-Learning: Run 2/5 Done - Time: 21.87\n",
      "5 Disks - Imitation-SMDP-Q-Learning: Run 3/5 Done - Time: 23.22\n",
      "5 Disks - Imitation-SMDP-Q-Learning: Run 4/5 Done - Time: 21.47\n",
      "5 Disks - Imitation-SMDP-Q-Learning: Run 5/5 Done - Time: 23.14\n",
      "Outfiled the results to results/5_disks_smdp_imi.txt.\n"
     ]
    }
   ],
   "source": [
    "# Run Learning 5 times for 5 Disk Environment\n",
    "num_disks = 5\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "env, agent, stats_5_smdp_imi = run_learning(\"Imitation-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                            num_episodes, max_steps,\n",
    "                                            log_episodes, log_freq,\n",
    "                                            save_fname=\"results/5_disks_smdp_imi.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Learning 5 times for 6 Disk Environment\n",
    "num_disks = 6\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "env, agent, stats_6_smdp_imi = run_learning(\"Imitation-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                            num_episodes, max_steps,\n",
    "                                            log_episodes, log_freq,\n",
    "                                            save_fname=\"results/6_disks_smdp_imi.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_episodes = 10\n",
    "log_freq = 20\n",
    "\n",
    "N = 5\n",
    "num_episodes = learning_setup[N][\"num_episodes\"]\n",
    "max_steps = learning_setup[N][\"max_steps\"]\n",
    "\n",
    "env = gym.make(\"Hanoi-v0\")\n",
    "env.set_env_parameters(num_disks=N, env_noise=0, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:  1 | Avg/Std Steps: 1017.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.10\n",
      "Ep: 21 | Avg/Std Steps: 309.50/18.50 | Avg/Std Ret: 0.00/18.50 | Success R: 0.20\n",
      "Ep: 41 | Avg/Std Steps: 683.67/370.92 | Avg/Std Ret: 0.01/370.92 | Success R: 0.30\n",
      "Ep: 61 | Avg/Std Steps: 1000.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 81 | Avg/Std Steps: 344.75/138.37 | Avg/Std Ret: 0.00/138.37 | Success R: 0.40\n",
      "Ep: 101 | Avg/Std Steps: 127.00/58.70 | Avg/Std Ret: 1.31/58.70 | Success R: 0.70\n",
      "Ep: 121 | Avg/Std Steps: 60.50/19.41 | Avg/Std Ret: 6.48/19.41 | Success R: 1.00\n",
      "Ep: 141 | Avg/Std Steps: 49.00/0.00 | Avg/Std Ret: 8.53/0.00 | Success R: 1.00\n",
      "Ep: 161 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 181 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 201 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 221 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 241 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 261 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 281 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 301 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 321 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 341 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 361 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 381 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 401 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 421 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 441 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 461 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 481 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 501 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 521 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 541 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 561 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 581 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 601 | Avg/Std Steps: 47.00/0.00 | Avg/Std Ret: 9.45/0.00 | Success R: 1.00\n",
      "Ep: 621 | Avg/Std Steps: 46.00/0.00 | Avg/Std Ret: 9.94/0.00 | Success R: 1.00\n",
      "Ep: 641 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 661 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 681 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 701 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 721 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 741 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 761 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 781 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 801 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 821 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 841 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 861 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 881 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 901 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 921 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 941 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 961 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 981 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1001 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1021 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1041 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1061 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1081 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1101 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1121 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1141 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1161 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1181 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1201 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1221 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n",
      "Ep: 1241 | Avg/Std Steps: 45.00/0.00 | Avg/Std Ret: 10.47/0.00 | Success R: 1.00\n"
     ]
    }
   ],
   "source": [
    "macros = get_optimal_macros(env, N-1, \"Sequitur\")\n",
    "agent = SMDP_Agent_Q(env, macros)\n",
    "params = learning_parameters(l_type=\"Transfer-SMDP-Q-Learning\")\n",
    "hist, er_buffer = smdp_q_learning(env, agent, num_episodes, max_steps,\n",
    "                                  **params,\n",
    "                                  log_freq=log_freq,\n",
    "                                  log_episodes=log_episodes, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Disks - Transfer-SMDP-Q-Learning: Run 1/5 Done - Time: 24.96\n",
      "5 Disks - Transfer-SMDP-Q-Learning: Run 2/5 Done - Time: 24.05\n",
      "5 Disks - Transfer-SMDP-Q-Learning: Run 3/5 Done - Time: 25.51\n",
      "5 Disks - Transfer-SMDP-Q-Learning: Run 4/5 Done - Time: 25.25\n",
      "5 Disks - Transfer-SMDP-Q-Learning: Run 5/5 Done - Time: 27.24\n",
      "Outfiled the results to results/5_disks_smdp_transfer_4_disks.txt.\n"
     ]
    }
   ],
   "source": [
    "# Run Learning 5 times for 5 Disk Environment with 4 disk grammar\n",
    "num_times = 5\n",
    "num_disks = 5\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "env, agent, stats_smdp_trans_5 = run_learning(\"Transfer-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                              num_episodes, max_steps,\n",
    "                                              log_episodes, log_freq,\n",
    "                                              transfer_distance=1,\n",
    "                                              save_fname=\"results/5_disks_smdp_transfer_4_disks.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times = 5\n",
    "num_disks = 6\n",
    "num_episodes = learning_setup[num_disks][\"num_episodes\"]\n",
    "max_steps = learning_setup[num_disks][\"max_steps\"]\n",
    "\n",
    "# Run Learning 5 times for 6 Disk Environment with 5 disk grammar\n",
    "env, agent, stats_smdp_trans_5 = run_learning(\"Transfer-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                              num_episodes, max_steps,\n",
    "                                              log_episodes, log_freq,\n",
    "                                              transfer_distance=1,\n",
    "                                              save_fname=\"results/6_disks_smdp_transfer_5_disks.txt\")\n",
    "\n",
    "# Run Learning 5 times for 6 Disk Environment with 4 disk grammar\n",
    "env, agent, stats_smdp_trans_4 = run_learning(\"Transfer-SMDP-Q-Learning\", num_times, num_disks,\n",
    "                                              num_episodes, max_steps,\n",
    "                                              log_episodes, log_freq,\n",
    "                                              transfer_distance=2,\n",
    "                                              save_fname=\"results/6_disks_smdp_transfer_4_disks.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online-Grammar-Macro-SMDP Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep:  1 | Avg/Std Steps: 244.33/60.37 | Avg/Std Ret: 0.01/60.37 | Success R: 0.30\n",
      "Ep: 21 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 41 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 61 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 81 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep:  1 | Avg/Std Steps: 153.00/72.21 | Avg/Std Ret: 0.72/72.21 | Success R: 0.60\n",
      "Ep: 21 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 41 | Avg/Std Steps: 19.00/0.00 | Avg/Std Ret: 39.72/0.00 | Success R: 1.00\n",
      "Ep: 61 | Avg/Std Steps: 16.00/0.00 | Avg/Std Ret: 46.33/0.00 | Success R: 1.00\n",
      "Ep: 81 | Avg/Std Steps: 16.00/0.00 | Avg/Std Ret: 46.33/0.00 | Success R: 1.00\n",
      "[[0.00000000e+00 2.44333333e+02 6.03673937e+01 9.60476128e-03\n",
      "  1.35103994e-02 3.00000000e-01]\n",
      " [2.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [4.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [6.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [8.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+02 1.53000000e+02 7.22103409e+01 7.24212190e-01\n",
      "  1.00658188e+00 6.00000000e-01]\n",
      " [1.20000000e+02 1.90000000e+01 0.00000000e+00 3.97214318e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.40000000e+02 1.90000000e+01 0.00000000e+00 3.97214318e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.60000000e+02 1.60000000e+01 0.00000000e+00 4.63291230e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.80000000e+02 1.60000000e+01 0.00000000e+00 4.63291230e+01\n",
      "  0.00000000e+00 1.00000000e+00]]\n",
      "Ep:  1 | Avg/Std Steps: 218.60/115.52 | Avg/Std Ret: 0.68/115.52 | Success R: 0.50\n",
      "Ep: 21 | Avg/Std Steps: 96.70/52.33 | Avg/Std Ret: 4.54/52.33 | Success R: 1.00\n",
      "Ep: 41 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 61 | Avg/Std Steps: 22.00/0.00 | Avg/Std Ret: 34.06/0.00 | Success R: 1.00\n",
      "Ep: 81 | Avg/Std Steps: 22.00/0.00 | Avg/Std Ret: 34.06/0.00 | Success R: 1.00\n",
      "[[0.00000000e+00 2.44333333e+02 6.03673937e+01 9.60476128e-03\n",
      "  1.35103994e-02 3.00000000e-01]\n",
      " [2.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [4.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [6.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [8.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+02 1.53000000e+02 7.22103409e+01 7.24212190e-01\n",
      "  1.00658188e+00 6.00000000e-01]\n",
      " [1.20000000e+02 1.90000000e+01 0.00000000e+00 3.97214318e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.40000000e+02 1.90000000e+01 0.00000000e+00 3.97214318e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.60000000e+02 1.60000000e+01 0.00000000e+00 4.63291230e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.80000000e+02 1.60000000e+01 0.00000000e+00 4.63291230e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [2.00000000e+02 2.18600000e+02 1.15520734e+02 6.79612263e-01\n",
      "  1.35347176e+00 5.00000000e-01]\n",
      " [2.20000000e+02 9.67000000e+01 5.23336412e+01 4.53517146e+00\n",
      "  7.34222293e+00 1.00000000e+00]\n",
      " [2.40000000e+02 5.00000000e+02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.60000000e+02 2.20000000e+01 0.00000000e+00 3.40561626e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [2.80000000e+02 2.20000000e+01 0.00000000e+00 3.40561626e+01\n",
      "  0.00000000e+00 1.00000000e+00]]\n",
      "Ep:  1 | Avg/Std Steps: 282.00/133.34 | Avg/Std Ret: 0.40/133.34 | Success R: 0.70\n",
      "Ep: 21 | Avg/Std Steps: 500.00/0.00 | Avg/Std Ret: 0.00/0.00 | Success R: 0.00\n",
      "Ep: 41 | Avg/Std Steps: 17.00/0.00 | Avg/Std Ret: 44.01/0.00 | Success R: 1.00\n",
      "Ep: 61 | Avg/Std Steps: 16.00/0.00 | Avg/Std Ret: 46.33/0.00 | Success R: 1.00\n",
      "Ep: 81 | Avg/Std Steps: 16.00/0.00 | Avg/Std Ret: 46.33/0.00 | Success R: 1.00\n",
      "[[0.00000000e+00 2.44333333e+02 6.03673937e+01 9.60476128e-03\n",
      "  1.35103994e-02 3.00000000e-01]\n",
      " [2.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [4.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [6.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [8.00000000e+01 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.00000000e+02 1.53000000e+02 7.22103409e+01 7.24212190e-01\n",
      "  1.00658188e+00 6.00000000e-01]\n",
      " [1.20000000e+02 1.90000000e+01 0.00000000e+00 3.97214318e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.40000000e+02 1.90000000e+01 0.00000000e+00 3.97214318e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.60000000e+02 1.60000000e+01 0.00000000e+00 4.63291230e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.80000000e+02 1.60000000e+01 0.00000000e+00 4.63291230e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [2.00000000e+02 2.18600000e+02 1.15520734e+02 6.79612263e-01\n",
      "  1.35347176e+00 5.00000000e-01]\n",
      " [2.20000000e+02 9.67000000e+01 5.23336412e+01 4.53517146e+00\n",
      "  7.34222293e+00 1.00000000e+00]\n",
      " [2.40000000e+02 5.00000000e+02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.60000000e+02 2.20000000e+01 0.00000000e+00 3.40561626e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [2.80000000e+02 2.20000000e+01 0.00000000e+00 3.40561626e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [3.00000000e+02 2.82000000e+02 1.33339524e+02 3.99031443e-01\n",
      "  9.63239945e-01 7.00000000e-01]\n",
      " [3.20000000e+02 5.00000000e+02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.40000000e+02 1.70000000e+01 0.00000000e+00 4.40126669e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [3.60000000e+02 1.60000000e+01 0.00000000e+00 4.63291230e+01\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [3.80000000e+02 1.60000000e+01 0.00000000e+00 4.63291230e+01\n",
      "  0.00000000e+00 1.00000000e+00]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "7",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-65b20ad99501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                        \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                        \u001b[0mlog_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                        verbose=True)\n\u001b[0m",
      "\u001b[0;32m~/Dropbox/PHD_ECN/PROJECTS/ActionGrammars/code/learning/smdp_q_learning.py\u001b[0m in \u001b[0;36msmdp_q_online_learning\u001b[0;34m(env, agent, init_q_eps, inter_update_eps, num_grammar_updates, max_steps, gamma, alpha, lambd, epsilon, log_freq, log_episodes, verbose)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mupdate_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_grammar_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;31m# Extract first grammar/macro productions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rollout_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         productions = get_macros(\"all\", sentence, num_primitives=6,\n\u001b[1;32m    122\u001b[0m                                  g_type=\"sequitur\", k=2)\n",
      "\u001b[0;32m~/Dropbox/PHD_ECN/PROJECTS/ActionGrammars/code/utils/general.py\u001b[0m in \u001b[0;36mget_rollout_policy\u001b[0;34m(env, agent, max_steps, record_macros, grammar)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreedy_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mer_buffer_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/PHD_ECN/PROJECTS/ActionGrammars/gym-hanoi/gym_hanoi/envs/hanoi_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transition_failure\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mmove\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction_to_move\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_allowed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 7"
     ]
    }
   ],
   "source": [
    "# Setup for N=4 Disk Towers of Hanoi Environment\n",
    "log_episodes = 10\n",
    "log_freq = 20\n",
    "\n",
    "init_q_eps = 100\n",
    "inter_update_eps=100\n",
    "num_grammar_updates=5\n",
    "\n",
    "N = 4\n",
    "max_steps = learning_setup[N][\"max_steps\"]\n",
    "\n",
    "env = gym.make(\"Hanoi-v0\")\n",
    "env.set_env_parameters(N, env_noise=0, verbose=False)\n",
    "\n",
    "agent = Agent_Q(env)\n",
    "params = learning_parameters(l_type=\"Q-Learning\")\n",
    "smdp_q_online_learning(env, agent, init_q_eps, inter_update_eps,\n",
    "                       num_grammar_updates, max_steps,\n",
    "                       **params,\n",
    "                       log_freq=log_freq, log_episodes=log_episodes,\n",
    "                       verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (AG)",
   "language": "python",
   "name": "ag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
